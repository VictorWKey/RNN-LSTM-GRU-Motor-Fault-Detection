# ğŸš€ GuÃ­a de Inicio RÃ¡pido - PrÃ¡ctica 02

## Modelos Recurrentes para SeÃ±ales de Motor

---

## âš¡ InstalaciÃ³n RÃ¡pida

### 1. Instalar dependencias

```bash
cd practica02
pip install -r requirements.txt
```

### 2. Verificar instalaciÃ³n de PyTorch

```bash
python -c "import torch; print(f'PyTorch {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
```

---

## ğŸ¯ Ejecutar Entrenamientos

### OpciÃ³n 1: Ejecutar TODO (Recomendado)

```bash
python run_all.py
```

Esto ejecutarÃ¡ secuencialmente:
1. Entrenamiento de clasificaciÃ³n (9 modelos)
2. Entrenamiento de regresiÃ³n (9 modelos)

**Tiempo estimado:** 2-4 horas (dependiendo de GPU/CPU)

### OpciÃ³n 2: Solo ClasificaciÃ³n

```bash
python train_classification.py
```

**Tiempo estimado:** 1-2 horas

### OpciÃ³n 3: Solo RegresiÃ³n

```bash
python train_regression.py
```

**Tiempo estimado:** 1-2 horas

### OpciÃ³n 4: Ejecutar selectivamente

```bash
# Solo clasificaciÃ³n
python run_all.py --classification-only

# Solo regresiÃ³n
python run_all.py --regression-only
```

---

## ğŸ“Š Â¿QuÃ© se genera?

Al finalizar, tendrÃ¡s:

### Checkpoints (modelos entrenados)
```
checkpoints/
â”œâ”€â”€ RNN_Base_classification_best.pth
â”œâ”€â”€ RNN_Deep_classification_best.pth
â”œâ”€â”€ RNN_ReLU_classification_best.pth
â”œâ”€â”€ LSTM_Base_classification_best.pth
â”œâ”€â”€ LSTM_Bidirectional_classification_best.pth
â”œâ”€â”€ LSTM_Stacked_classification_best.pth
â”œâ”€â”€ GRU_Base_classification_best.pth
â”œâ”€â”€ GRU_Bidirectional_classification_best.pth
â”œâ”€â”€ GRU_Stacked_classification_best.pth
â””â”€â”€ ... (lo mismo para regression)
```

### Figuras
```
figures/
â”œâ”€â”€ *_classification_history.png      (Curvas de entrenamiento)
â”œâ”€â”€ *_classification_confusion_matrix.png (Matrices de confusiÃ³n)
â”œâ”€â”€ *_regression_predictions.png      (Scatter plots)
â”œâ”€â”€ *_regression_timeseries.png       (Series temporales)
â”œâ”€â”€ classification_model_comparison.png
â””â”€â”€ regression_model_comparison.png
```

### Tablas de Resultados
```
results/
â”œâ”€â”€ classification_results.csv  (Para Excel/Google Sheets)
â”œâ”€â”€ classification_results.tex  (Para LaTeX)
â”œâ”€â”€ regression_results.csv
â””â”€â”€ regression_results.tex
```

---

## ğŸ”§ ConfiguraciÃ³n RÃ¡pida

### Cambiar HiperparÃ¡metros

Editar `config.py`:

```python
TRAIN_CONFIG = {
    'epochs': 80,           # NÃºmero de Ã©pocas
    'batch_size': 64,       # TamaÃ±o de batch
    'learning_rate': 0.001, # Learning rate
}
```

### Cambiar TamaÃ±o de Ventana

```python
DATA_CONFIG = {
    'classification': {
        'window_size': 64,  # TamaÃ±o de ventana temporal
    }
}
```

---

## ğŸ“ˆ Monitoreo durante Entrenamiento

Durante el entrenamiento verÃ¡s output como:

```
================================================================================
ENTRENANDO: LSTM_Bidirectional
================================================================================
HipÃ³tesis: La bidireccionalidad permitirÃ¡ al modelo capturar contexto...
--------------------------------------------------------------------------------

Ã‰poca   1/80: Train Loss=1.4523, Train Acc=42.34% | Val Loss=1.2845, Val Acc=48.23%, Val F1=45.67% | Time=5.23s
Ã‰poca  10/80: Train Loss=0.8234, Train Acc=68.45% | Val Loss=0.7912, Val Acc=72.34%, Val F1=70.12% | Time=5.18s
Ã‰poca  20/80: Train Loss=0.5123, Train Acc=82.67% | Val Loss=0.5456, Val Acc=80.45%, Val F1=78.89% | Time=5.21s
...
Ã‰poca  80/80: Train Loss=0.1234, Train Acc=95.23% | Val Loss=0.2345, Val Acc=91.34%, Val F1=89.67% | Time=5.19s

âœ… Entrenamiento completado en 418.32s (6.97 min)
   Mejor val loss: 0.2156

================================================================================
EVALUACIÃ“N EN TEST: LSTM_Bidirectional
================================================================================

ğŸ“Š Resultados en Test:
   Accuracy: 90.12%
   F1-Score (macro): 88.45%
```

---

## âš™ï¸ OptimizaciÃ³n para Pruebas RÃ¡pidas

Si quieres hacer pruebas rÃ¡pidas, edita `config.py`:

```python
TRAIN_CONFIG = {
    'epochs': 10,          # Reducir Ã©pocas
    'batch_size': 128,     # Aumentar batch size
}

DATA_CONFIG = {
    'regression': {
        'T': 1000,         # Menos puntos temporales
    }
}
```

---

## ğŸ› SoluciÃ³n de Problemas Comunes

### Error: CUDA out of memory

```python
# En config.py, reducir batch size
TRAIN_CONFIG = {
    'batch_size': 32  # Era 64
}
```

### Entrenamiento muy lento (CPU)

```python
# Reducir complejidad
TRAIN_CONFIG = {
    'epochs': 40,  # En lugar de 80
}

MODEL_CONFIG = {
    'lstm': {
        'base': {
            'hidden_size': 32,  # En lugar de 64
        }
    }
}
```

### Dataset no encontrado

```bash
# Verificar estructura
ls Dataset/
# DeberÃ­a mostrar: SC_HLT SC_A0_B0_C1 SC_A0_B0_C2 SC_A0_B0_C3 SC_A0_B0_C4
```

---

## ğŸ“ Generar Reporte

### 1. Recopilar Resultados

DespuÃ©s de entrenar, los resultados estÃ¡n en:
- `results/classification_results.csv`
- `results/regression_results.csv`
- `figures/*.png`

### 2. Estructura del Reporte (IMRA)

#### I. IntroducciÃ³n
- Contexto de RNNs para seÃ±ales
- Problema: 5 clases de motor
- Objetivos
- HipÃ³tesis (ver `HIPOTESIS_Y_ANALISIS.md`)

#### II. MetodologÃ­a
- Dataset (5 clases, 3 features)
- Preprocesamiento (ventanas, normalizaciÃ³n)
- Modelos (RNN, LSTM, GRU + variantes)
- Protocolo de entrenamiento

#### III. Resultados
- **Tabla I:** ClasificaciÃ³n - copiar de `classification_results.csv`
- **Tabla II:** RegresiÃ³n - copiar de `regression_results.csv`
- **Figuras:** Usar PNGs de `figures/`

#### IV. AnÃ¡lisis
- ValidaciÃ³n de hipÃ³tesis
- Comparaciones RNN/LSTM/GRU
- AnÃ¡lisis de errores (matriz confusiÃ³n)
- Conclusiones

---

## ğŸ“ Checklist de Entrega

- [ ] CÃ³digo ejecutado completamente
- [ ] Checkpoints guardados en `checkpoints/`
- [ ] Todas las figuras generadas en `figures/`
- [ ] Tablas CSV y LaTeX en `results/`
- [ ] Reporte PDF con estructura IMRA
- [ ] AnÃ¡lisis de hipÃ³tesis completado
- [ ] ComparaciÃ³n de modelos documentada
- [ ] CÃ³digo comentado y limpio

---

## ğŸ’¡ Consejos para el Reporte

1. **No inventar resultados:** Usar los reales generados
2. **Analizar tendencias:** No solo reportar nÃºmeros
3. **Comparar con hipÃ³tesis:** Â¿Se confirmaron?
4. **Explicar diferencias:** Si hipÃ³tesis fallÃ³, Â¿por quÃ©?
5. **Matrices de confusiÃ³n:** Analizar patrones de error
6. **Figuras profesionales:** Ya estÃ¡n en alta resoluciÃ³n (300 DPI)

---

## ğŸ“š Recursos Adicionales

- `README.md` - DocumentaciÃ³n completa
- `HIPOTESIS_Y_ANALISIS.md` - GuÃ­a de anÃ¡lisis detallada
- `config.py` - ConfiguraciÃ³n con comentarios
- `models/rnn_models.py` - Arquitecturas con docstrings

---

## ğŸš€ Siguiente Nivel (Opcional)

### Agregar Nueva Variante

1. Definir configuraciÃ³n en `config.py`:
```python
MODEL_CONFIG = {
    'lstm': {
        'variants': {
            'attention': {
                'hidden_size': 64,
                'num_layers': 1,
                'use_attention': True  # Nueva feature
            }
        }
    }
}
```

2. Implementar en `models/rnn_models.py`
3. Agregar instancia en `train_classification.py`
4. Ejecutar entrenamiento

---

## âœ… VerificaciÃ³n Final

Antes de entregar, ejecuta:

```bash
# Verificar estructura
ls -R practica02/

# Verificar resultados
ls checkpoints/ figures/ results/

# Contar modelos entrenados
ls checkpoints/*.pth | wc -l
# DeberÃ­a dar 18 (9 clasificaciÃ³n + 9 regresiÃ³n)

# Verificar figuras
ls figures/*.png | wc -l
# DeberÃ­a dar al menos 36
```

---

**Â¡Ã‰xito en tu prÃ¡ctica! ğŸ‰**

Si tienes dudas, revisa:
1. `README.md` para documentaciÃ³n completa
2. `HIPOTESIS_Y_ANALISIS.md` para anÃ¡lisis detallado
3. Comentarios en el cÃ³digo

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
