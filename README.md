# PrÃ¡ctica 02: Modelos Recurrentes para SeÃ±ales de Motor

**Asignatura:** Aprendizaje Profundo  
**InstituciÃ³n:** Universidad de Guanajuato  
**Fecha:** Noviembre 2025

---

## ğŸ“‹ DescripciÃ³n

Esta prÃ¡ctica implementa y compara tres arquitecturas recurrentes (RNN, LSTM y GRU) para dos tareas principales:

1. **ClasificaciÃ³n:** Identificar el estado de salud del motor entre 13 clases (1 sano + 4 niveles de falla Ã— 3 fases)
2. **RegresiÃ³n:** PredicciÃ³n de series temporales

Para cada arquitectura se implementan:
- **Modelo base:** ConfiguraciÃ³n estÃ¡ndar
- **Variante 1:** ModificaciÃ³n arquitectural (ej: bidireccionalidad)
- **Variante 2:** ModificaciÃ³n adicional (ej: apilamiento de capas, dropout)

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
practica02/
â”œâ”€â”€ config.py                      # ConfiguraciÃ³n central del proyecto
â”œâ”€â”€ train_classification.py        # Script principal para clasificaciÃ³n
â”œâ”€â”€ train_regression.py            # Script principal para regresiÃ³n
â”œâ”€â”€ requirements.txt               # Dependencias de Python
â”œâ”€â”€ README.md                      # Este archivo
â”‚
â”œâ”€â”€ models/                        # Modelos RNN, LSTM, GRU
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ rnn_models.py
â”‚
â”œâ”€â”€ utils/                         # Utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_utils.py             # Carga y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ training_utils.py         # Funciones de entrenamiento
â”‚   â””â”€â”€ visualization.py          # VisualizaciÃ³n de resultados
â”‚
â”œâ”€â”€ Dataset/                       # Datos de seÃ±ales de motor
â”‚   â”œâ”€â”€ SC_HLT/                   # Clase sana
â”‚   â”œâ”€â”€ SC_A0_B0_C1-4/            # Falla nivel 1-4 - Fase C
â”‚   â”œâ”€â”€ SC_A0_B1-4_C0/            # Falla nivel 1-4 - Fase B
â”‚   â””â”€â”€ SC_A1-4_B0_C0/            # Falla nivel 1-4 - Fase A
â”‚
â”œâ”€â”€ checkpoints/                   # Modelos guardados (generado)
â”œâ”€â”€ figures/                       # GrÃ¡ficas y visualizaciones (generado)
â”œâ”€â”€ results/                       # Tablas de resultados (generado)
â””â”€â”€ logs/                          # Logs de entrenamiento (generado)
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Requisitos Previos

- Python 3.8+
- CUDA 11.8+ (opcional, para GPU)
- pip

### 2. Instalar Dependencias

```bash
# Navegar al directorio del proyecto
cd practica02

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Linux/Mac
# venv\Scripts\activate   # En Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 3. Verificar InstalaciÃ³n

```bash
# Verificar PyTorch y CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

---

## ğŸ“Š Dataset

### ClasificaciÃ³n de SeÃ±ales de Motor

- **13 clases totales:**
  - `SC_HLT`: Motor sano (healthy)
  
  **Fase C (4 niveles):**
  - `SC_A0_B0_C1`: Falla nivel 1 - Fase C
  - `SC_A0_B0_C2`: Falla nivel 2 - Fase C
  - `SC_A0_B0_C3`: Falla nivel 3 - Fase C
  - `SC_A0_B0_C4`: Falla nivel 4 - Fase C
  
  **Fase B (4 niveles):**
  - `SC_A0_B1_C0`: Falla nivel 1 - Fase B
  - `SC_A0_B2_C0`: Falla nivel 2 - Fase B
  - `SC_A0_B3_C0`: Falla nivel 3 - Fase B
  - `SC_A0_B4_C0`: Falla nivel 4 - Fase B
  
  **Fase A (4 niveles):**
  - `SC_A1_B0_C0`: Falla nivel 1 - Fase A
  - `SC_A2_B0_C0`: Falla nivel 2 - Fase A
  - `SC_A3_B0_C0`: Falla nivel 3 - Fase A
  - `SC_A4_B0_C0`: Falla nivel 4 - Fase A

- **Formato:** Archivos CSV con 3 columnas (seÃ±ales de 3 fases del motor)
- **5 archivos por clase** con ~1000 muestras cada uno

### RegresiÃ³n de Series Temporales

- **Serie sintÃ©tica generada automÃ¡ticamente**
- 5000 puntos temporales
- Componentes: tendencia + estacionalidad + ruido

---

## ğŸ¯ Uso

### Entrenamiento de ClasificaciÃ³n

```bash
python train_classification.py
```

Este script:
1. Carga las seÃ±ales de motor
2. Crea ventanas temporales de tamaÃ±o 64
3. Entrena 9 modelos (3 arquitecturas Ã— 3 variantes)
4. Genera grÃ¡ficas de curvas de entrenamiento y matrices de confusiÃ³n
5. Guarda resultados en tablas CSV y LaTeX

**ParÃ¡metros principales** (en `config.py`):
- Ã‰pocas: 80
- Batch size: 64
- Learning rate: 0.001
- Window size: 64

### Entrenamiento de RegresiÃ³n

```bash
python train_regression.py
```

Similar al de clasificaciÃ³n, pero para predicciÃ³n de series temporales.

---

## ğŸ—ï¸ Modelos Implementados

### 1. RNN (Vanilla/Elman)

**Base:**
- 1 capa RNN
- Hidden size: 128
- ActivaciÃ³n: tanh

**Variantes:**
- **RNN_Deep:** 2 capas apiladas
- **RNN_ReLU:** ActivaciÃ³n ReLU en lugar de tanh

### 2. LSTM (Long Short-Term Memory)

**Base:**
- 1 capa LSTM
- Hidden size: 64

**Variantes:**
- **LSTM_Bidirectional:** LSTM bidireccional
- **LSTM_Stacked:** 2 capas LSTM con dropout 0.2

### 3. GRU (Gated Recurrent Unit)

**Base:**
- 1 capa GRU
- Hidden size: 64

**Variantes:**
- **GRU_Bidirectional:** GRU bidireccional
- **GRU_Stacked:** 2 capas GRU con dropout 0.2

---

## ğŸ“ˆ MÃ©tricas Evaluadas

### ClasificaciÃ³n
- **Accuracy:** PrecisiÃ³n general
- **F1-Score (macro):** Media armÃ³nica de precisiÃ³n y recall
- **Matriz de confusiÃ³n:** AnÃ¡lisis detallado de errores
- **Classification report:** MÃ©tricas por clase

### RegresiÃ³n
- **MSE:** Error cuadrÃ¡tico medio
- **RMSE:** RaÃ­z del error cuadrÃ¡tico medio
- **MAE:** Error absoluto medio
- **RÂ²:** Coeficiente de determinaciÃ³n

---

## ğŸ“ Resultados Generados

DespuÃ©s de ejecutar los scripts, se generan:

### Checkpoints
```
checkpoints/
â”œâ”€â”€ RNN_Base_classification_best.pth
â”œâ”€â”€ LSTM_Bidirectional_classification_best.pth
â”œâ”€â”€ GRU_Stacked_regression_best.pth
â””â”€â”€ ...
```

### Figuras
```
figures/
â”œâ”€â”€ RNN_Base_classification_history.png
â”œâ”€â”€ LSTM_Bidirectional_classification_confusion_matrix.png
â”œâ”€â”€ GRU_Stacked_regression_predictions.png
â”œâ”€â”€ classification_model_comparison.png
â””â”€â”€ regression_model_comparison.png
```

### Tablas de Resultados
```
results/
â”œâ”€â”€ classification_results.csv
â”œâ”€â”€ classification_results.tex
â”œâ”€â”€ regression_results.csv
â””â”€â”€ regression_results.tex
```

---

## ğŸ”¬ HipÃ³tesis y Preguntas de InvestigaciÃ³n

### HipÃ³tesis por Variante

**RNN:**
- **Base:** CapturarÃ¡ patrones bÃ¡sicos en seÃ±ales
- **Deep:** Mayor profundidad mejorarÃ¡ F1-Score
- **ReLU:** EvitarÃ¡ gradiente desvaneciente

**LSTM:**
- **Base:** CapturarÃ¡ dependencias a largo plazo
- **Bidirectional:** Contexto pasado/futuro mejorarÃ¡ detecciÃ³n de fallas
- **Stacked:** Dropout regularizarÃ¡ y mejorarÃ¡ generalizaciÃ³n

**GRU:**
- **Base:** Rendimiento similar a LSTM con menos costo
- **Bidirectional:** MejorarÃ¡ detecciÃ³n bidireccional
- **Stacked:** AumentarÃ¡ capacidad manteniendo eficiencia

### Preguntas de InvestigaciÃ³n

1. Â¿SuperarÃ¡ LSTM a RNN simple en dependencias largas?
2. Â¿MejorarÃ¡ la bidireccionalidad el F1-Score en fallas incipientes?
3. Â¿GRU lograrÃ¡ balance Ã³ptimo entre rendimiento y eficiencia vs LSTM?
4. Â¿Mayor profundidad mejorarÃ¡ mÃ©tricas a costa de tiempo?
5. Â¿QuÃ© arquitectura es mÃ¡s robusta ante overfitting?

---

## ğŸ› ï¸ PersonalizaciÃ³n

### Modificar HiperparÃ¡metros

Editar `config.py`:

```python
TRAIN_CONFIG = {
    'epochs': 100,          # Cambiar nÃºmero de Ã©pocas
    'batch_size': 128,      # Cambiar tamaÃ±o de batch
    'learning_rate': 0.0001 # Cambiar learning rate
}
```

### Agregar Nueva Variante

1. Editar `config.py` en `MODEL_CONFIG`
2. Agregar configuraciÃ³n en `HYPOTHESES`
3. Instanciar modelo en `train_classification.py` o `train_regression.py`

---

## ğŸ“Š AnÃ¡lisis de Resultados

Los resultados deben analizarse considerando:

1. **RNN vs LSTM/GRU:** Â¿Problema de gradiente desvaneciente en RNN?
2. **LSTM vs GRU:** Â¿Justifica LSTM su mayor costo computacional?
3. **ClasificaciÃ³n vs RegresiÃ³n:** Â¿QuÃ© tarea fue mÃ¡s difÃ­cil?
4. **Errores:** AnÃ¡lisis de matriz de confusiÃ³n y scatter plots
5. **Variantes:** Â¿Se validaron las hipÃ³tesis?

---

## ğŸ› Troubleshooting

### Error: CUDA out of memory
```bash
# Reducir batch size en config.py
TRAIN_CONFIG = {
    'batch_size': 32  # Era 64
}
```

### Error: No se encuentra el dataset
```bash
# Verificar que existe Dataset/ con las carpetas de clases
ls Dataset/
```

### Entrenamiento muy lento
```bash
# Verificar que estÃ¡ usando GPU
python -c "import torch; print(torch.cuda.is_available())"

# Reducir nÃºmero de Ã©pocas para pruebas
TRAIN_CONFIG = {
    'epochs': 20  # En lugar de 80
}
```

---

## ğŸ“ Reporte AcadÃ©mico

Los resultados de esta prÃ¡ctica deben documentarse siguiendo la filosofÃ­a **IMRA**:

1. **IntroducciÃ³n:** Contexto, problema, objetivos, hipÃ³tesis
2. **MetodologÃ­a:** Datos, modelos, protocolo de entrenamiento
3. **Resultados:** Tablas, figuras, mÃ©tricas
4. **AnÃ¡lisis:** DiscusiÃ³n de hipÃ³tesis, comparaciones, errores

---

## ğŸ‘¥ Autor

PrÃ¡ctica desarrollada para el curso de **Aprendizaje Profundo**  
Universidad de Guanajuato

---

## ğŸ“œ Licencia

Este proyecto es material educativo para uso acadÃ©mico.

---

## ğŸ™ Agradecimientos

- CÃ³digo base inspirado en ejemplos de PyTorch
- Dataset de seÃ±ales de motor (sintÃ©tico para demostraciÃ³n)
- Instructor: M.I. Juan JosÃ© CÃ¡rdenas Cornejo

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
